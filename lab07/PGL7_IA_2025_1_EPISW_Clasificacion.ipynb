{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08GI-PhT2nXD"
      },
      "source": [
        "# Práctica Guiada de Laboratorio 7 - Curso IA 2025-1 Grupo 1 EPISW\n",
        "# Implementación de técnicas de Machine Learning - Clasificación\n",
        "### Prof. Rolando A. Maguiña Pérez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHoPbM8M2nXM"
      },
      "source": [
        "# Introducción\n",
        "En la presente práctica, a realizarse el 15 de Mayo del 2025, se abordará el problema denominado “Predicción de cáncer de mama” mediante un par de técnicas  del área de la IA denominada  `Machine Learning`. Luego de la presentación del problema, se entrenarán sus respectivos algoritmos para \"aprender a clasificar\" si los datos corresponden a un cáncer de mama o no; luego, se evaluarán dichos algoritmos sobre un conjunto de datos de validación, y se elegirá el que ofrezca mejores métricas de evaluación para elaborar nuestro modelo predictivo.\n",
        "\n",
        "En esas actividades se usará la biblioteca de aprendizaje automático para el lenguaje de programación Python llamada  [scikit-learn](https://scikit-learn.org/stable/).\n",
        "\n",
        "Las principales actividades a desarrollar en esta práctica son:\n",
        "* Instalación de la biblioteca llamada scikit-learn.\n",
        "* Construcción de un par de algoritmos del área de la IA denominada  `Machine Learning` mediante el scikit-learn.\n",
        "* Entrenamiento para obtener el modelo.\n",
        "* Validación del modelo.\n",
        "* Selección de la técnica.\n",
        "\n",
        "Luego de realizar estas actividades, se plantearán algunas preguntas que los alumnos deberán resolver.\n",
        "\n",
        "# Objetivos\n",
        "Los objetivos de esta Práctica son:\n",
        "- Conocer la biblioteca de aprendizaje automático llamada `scikit-learn`.\n",
        "- Conocer la implementación de un par de técnicas de Machine Learning con `scikit-learn`.\n",
        "- Aprender las etapas del procesamiento de una data: entrenamiento/validación.\n",
        "- Obtener el mejor modelo que resuelva el problema planteado.\n",
        "\n",
        "**Nota: esta Práctica podrá desarrollarse en grupos de tres alumnos. Sólo será válida para los alumnos que asistieron a la clase de teoría**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BLflx-x2nXQ"
      },
      "source": [
        "# scikit-learn\n",
        "## Introducción al scikit-learn\n",
        "[scikit-learn](https://scikit-learn.org/stable/) es una de las herramientas computacionales más populares y usadas en Machine Learning. Incluye algoritmos para abordar problemas de clasificación, regresión y clustering; asimismo, para otras tareas relacionadas, tales como, reducción de dimensionalidad, preprocesamiento del dataset, entre otras.\n",
        "\n",
        "Para esta Práctica se deberá instalar previamente, para luego ser usada en la resolución de un ejercicio.\n",
        "\n",
        "## Instalación del scikit-learn\n",
        "Instalar el scikit-learn siguiendo lo indicado en [Installing the latest release](https://scikit-learn.org/stable/install.html#install-official-release).\n",
        "\n",
        "Se puede usar el sistema de gestión de paquetes llamado `pip` o el `conda`. Se recomienda usar el segundo de los nombrados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLTVp9po2nXS"
      },
      "source": [
        "# Predicción de cáncer de mama\n",
        "## Introducción al problema\n",
        "El cáncer es una de las principales causas de mortalidad en todo el mundo y la investigación en su diagnóstico y tratamiento se ha convertido en un tema de vital importancia para la comunidad científica. La prevención sigue siendo un reto, y la mejor manera de aumentar la supervivencia de los pacientes es a través de la detección temprana.\n",
        "\n",
        "Si las células cancerosas son detectadas antes de su diseminación a otros órganos, la tasa de supervivencia es superior al 97%. Por esta razón, el uso y perfeccionamiento de clasificadores automáticos que den soporte al diagnóstico médico se ha incrementado notablemente en los últimos tiempos. Estos sistemas de clasificación tratan de minimizar los posibles errores producidos por los especialistas, aumentar el número de diagnosis que pueden realizar en un tiempo dado, y su porcentaje de éxito.\n",
        "\n",
        "## Planteamiento del problema ejm\n",
        "Se trata del problema de la predicción de cáncer de mama, o breast cancer, un problema bastante conocido en esta área. Consiste en que el sistema computacional \"aprenda a clasificar\" si los datos corresponden a un tumor benigno o maligno; le debemos enseñar a efectuar esa tarea. Para ello, usaremos un dataset con ejms de personas que han tenido esa enfermedad (ejms positivos) y ejms de personas que no la han tenido  (ejms negativos). El sistema estará basado en una técnica inteligente, una correspondiente al área de la IA llamada Machine Learning.\n",
        "\n",
        "La base de datos del cáncer de mama de Wisconsin (WBCD) se tomará para la clasificación  de cáncer de mama. La WBCD consta de 699 muestras. Cada registro de la base de datos tiene nueve atributos. Los atributos son numéricos, y es preciso hacer cambios de escala o de unidades, y permite su aproximación como problema de clasificación.\n",
        "\n",
        "Consta de 9 o atributos entradas basadas en características de las células:\n",
        "\n",
        "1. Espesor Macizo\n",
        "2. Uniformidad de tamaño de celula\n",
        "3. La uniformidad de la forma de la célula\n",
        "4. Adherencia Marginal\n",
        "5. Solo tamaño de células epiteliales\n",
        "6. Núcleos desnudos\n",
        "7. Bland Chromatin\n",
        "8. Nucleolos normal\n",
        "9. Mitosis\n",
        "\n",
        "## Solución del problema ejm\n",
        "Los pasos que vamos a dar para resolver este problema son los siguientes:  \n",
        "  - Carga de los datos y módulos/bibliotecas necesarias para este ejemplo.\n",
        "  - Exploración de los datos.\n",
        "  - Entrenamiento de los dos algoritmos seleccionados.\n",
        "  - Aplicación de los modelos para hacer predicciones a partir de lo «aprendido» y su respectiva evaluación para seleccionar el modelo más adecuado para este caso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt2VrftL2nXT"
      },
      "source": [
        "### Carga de los módulos/bibliotecas y la data\n",
        "Hay una gran variedad de bibliotecas (librerías) que tenemos disponibles y en cada una de ellas, a su vez, hay módulos distintos.  Pero para poder utilizar, tanto las librerías como los módulos,  hay que importarlos explícitamente (salvo la librería estándar).\n",
        "\n",
        "Para el problema ejemplo importaremos primero los módulos/librerías que necesitamos para este experimento en particular.  A continuación, se cargará la data; se hará directamente desde el *sklearn*.\n",
        "\n",
        "### Carga de los módulos/bibliotecas y la data\n",
        "Hay una gran variedad de bibliotecas (librerías) que tenemos disponibles y en cada una de ellas, a su vez, hay módulos distintos.  Pero para poder utilizar, tanto las librerías como los módulos,  hay que importarlos explícitamente (salvo la librería estándar).\n",
        "\n",
        "Para el problema ejemplo importaremos primero los módulos/librerías que necesitamos para este experimento en particular.  A continuación, se cargará la data. Se hará directamente desde el *sklearn*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 899,
      "metadata": {
        "id": "bWmoqR6w2nXV"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 900,
      "metadata": {
        "id": "6ppCt1dn2nXZ",
        "outputId": "457b3e35-ecd1-4d95-b1a7-0bf55f4d2319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
            "        1.189e-01],\n",
            "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
            "        8.902e-02],\n",
            "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
            "        8.758e-02],\n",
            "       ...,\n",
            "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
            "        7.820e-02],\n",
            "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
            "        1.240e-01],\n",
            "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
            "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
            "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
            "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
            "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 569\\n\\n:Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n:Attribute Information:\\n    - radius (mean of distances from center to points on the perimeter)\\n    - texture (standard deviation of gray-scale values)\\n    - perimeter\\n    - area\\n    - smoothness (local variation in radius lengths)\\n    - compactness (perimeter^2 / area - 1.0)\\n    - concavity (severity of concave portions of the contour)\\n    - concave points (number of concave portions of the contour)\\n    - symmetry\\n    - fractal dimension (\"coastline approximation\" - 1)\\n\\n    The mean, standard error, and \"worst\" or largest (mean of the three\\n    worst/largest values) of these features were computed for each image,\\n    resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n    10 is Radius SE, field 20 is Worst Radius.\\n\\n    - class:\\n            - WDBC-Malignant\\n            - WDBC-Benign\\n\\n:Summary Statistics:\\n\\n===================================== ====== ======\\n                                        Min    Max\\n===================================== ====== ======\\nradius (mean):                        6.981  28.11\\ntexture (mean):                       9.71   39.28\\nperimeter (mean):                     43.79  188.5\\narea (mean):                          143.5  2501.0\\nsmoothness (mean):                    0.053  0.163\\ncompactness (mean):                   0.019  0.345\\nconcavity (mean):                     0.0    0.427\\nconcave points (mean):                0.0    0.201\\nsymmetry (mean):                      0.106  0.304\\nfractal dimension (mean):             0.05   0.097\\nradius (standard error):              0.112  2.873\\ntexture (standard error):             0.36   4.885\\nperimeter (standard error):           0.757  21.98\\narea (standard error):                6.802  542.2\\nsmoothness (standard error):          0.002  0.031\\ncompactness (standard error):         0.002  0.135\\nconcavity (standard error):           0.0    0.396\\nconcave points (standard error):      0.0    0.053\\nsymmetry (standard error):            0.008  0.079\\nfractal dimension (standard error):   0.001  0.03\\nradius (worst):                       7.93   36.04\\ntexture (worst):                      12.02  49.54\\nperimeter (worst):                    50.41  251.2\\narea (worst):                         185.2  4254.0\\nsmoothness (worst):                   0.071  0.223\\ncompactness (worst):                  0.027  1.058\\nconcavity (worst):                    0.0    1.252\\nconcave points (worst):               0.0    0.291\\nsymmetry (worst):                     0.156  0.664\\nfractal dimension (worst):            0.055  0.208\\n===================================== ====== ======\\n\\n:Missing Attribute Values: None\\n\\n:Class Distribution: 212 - Malignant, 357 - Benign\\n\\n:Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n:Donor: Nick Street\\n\\n:Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. dropdown:: References\\n\\n  - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\\n    for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\\n    Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n    San Jose, CA, 1993.\\n  - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\\n    prognosis via linear programming. Operations Research, 43(4), pages 570-577,\\n    July-August 1995.\\n  - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n    to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\\n    163-171.\\n', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
            "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
            "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
            "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
            "       'smoothness error', 'compactness error', 'concavity error',\n",
            "       'concave points error', 'symmetry error',\n",
            "       'fractal dimension error', 'worst radius', 'worst texture',\n",
            "       'worst perimeter', 'worst area', 'worst smoothness',\n",
            "       'worst compactness', 'worst concavity', 'worst concave points',\n",
            "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'breast_cancer.csv', 'data_module': 'sklearn.datasets.data'}\n"
          ]
        }
      ],
      "source": [
        "dataset = datasets.load_breast_cancer()\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6biAu8U2nXe"
      },
      "source": [
        "### Exploración de los datos\n",
        "\n",
        "En esta etapa se analizarán las características de los datos, tales como su dimensión, qué aspecto tienen, se hará también un pequeño análisis estadístico de sus atributos y se les agrupará por clases. Cada una de estas acciones implica la ejecución  de un solo comando que, además se podrá reutilizar en proyectos futuros. En particular, se usará la función `shape`, que proporcionará las dimensiones del dataset, la función `head`, que mostrará los datos (se le puede indicar incluso el número de registros que se desea, muestre), y la función `describe`, que dará valores estadísticos sobre el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 901,
      "metadata": {
        "id": "75RNxwzf2nXf",
        "outputId": "86c30f16-f5fd-4ccd-9238-9f9803a27eef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Información en el dataset:\n",
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Información en el dataset:')\n",
        "print(dataset.keys())\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhFK3JXV2nXh"
      },
      "source": [
        "Verificamos las características del dataset. Usamos la clave `DESCR`, la cual proporciona una explicación de la estructura del conjunto de datos. Para leerlo, use la función print():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 902,
      "metadata": {
        "id": "hB-7UpeP2nXj",
        "outputId": "862c68de-e3cd-4f0f-88e2-a493faac4bec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Características del dataset:\n",
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            ":Number of Instances: 569\n",
            "\n",
            ":Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            ":Attribute Information:\n",
            "    - radius (mean of distances from center to points on the perimeter)\n",
            "    - texture (standard deviation of gray-scale values)\n",
            "    - perimeter\n",
            "    - area\n",
            "    - smoothness (local variation in radius lengths)\n",
            "    - compactness (perimeter^2 / area - 1.0)\n",
            "    - concavity (severity of concave portions of the contour)\n",
            "    - concave points (number of concave portions of the contour)\n",
            "    - symmetry\n",
            "    - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "    The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "    worst/largest values) of these features were computed for each image,\n",
            "    resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
            "    10 is Radius SE, field 20 is Worst Radius.\n",
            "\n",
            "    - class:\n",
            "            - WDBC-Malignant\n",
            "            - WDBC-Benign\n",
            "\n",
            ":Summary Statistics:\n",
            "\n",
            "===================================== ====== ======\n",
            "                                        Min    Max\n",
            "===================================== ====== ======\n",
            "radius (mean):                        6.981  28.11\n",
            "texture (mean):                       9.71   39.28\n",
            "perimeter (mean):                     43.79  188.5\n",
            "area (mean):                          143.5  2501.0\n",
            "smoothness (mean):                    0.053  0.163\n",
            "compactness (mean):                   0.019  0.345\n",
            "concavity (mean):                     0.0    0.427\n",
            "concave points (mean):                0.0    0.201\n",
            "symmetry (mean):                      0.106  0.304\n",
            "fractal dimension (mean):             0.05   0.097\n",
            "radius (standard error):              0.112  2.873\n",
            "texture (standard error):             0.36   4.885\n",
            "perimeter (standard error):           0.757  21.98\n",
            "area (standard error):                6.802  542.2\n",
            "smoothness (standard error):          0.002  0.031\n",
            "compactness (standard error):         0.002  0.135\n",
            "concavity (standard error):           0.0    0.396\n",
            "concave points (standard error):      0.0    0.053\n",
            "symmetry (standard error):            0.008  0.079\n",
            "fractal dimension (standard error):   0.001  0.03\n",
            "radius (worst):                       7.93   36.04\n",
            "texture (worst):                      12.02  49.54\n",
            "perimeter (worst):                    50.41  251.2\n",
            "area (worst):                         185.2  4254.0\n",
            "smoothness (worst):                   0.071  0.223\n",
            "compactness (worst):                  0.027  1.058\n",
            "concavity (worst):                    0.0    1.252\n",
            "concave points (worst):               0.0    0.291\n",
            "symmetry (worst):                     0.156  0.664\n",
            "fractal dimension (worst):            0.055  0.208\n",
            "===================================== ====== ======\n",
            "\n",
            ":Missing Attribute Values: None\n",
            "\n",
            ":Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            ":Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            ":Donor: Nick Street\n",
            "\n",
            ":Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. dropdown:: References\n",
            "\n",
            "  - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\n",
            "    for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\n",
            "    Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "    San Jose, CA, 1993.\n",
            "  - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\n",
            "    prognosis via linear programming. Operations Research, 43(4), pages 570-577,\n",
            "    July-August 1995.\n",
            "  - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "    to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\n",
            "    163-171.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Características del dataset:')\n",
        "print(dataset.DESCR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JYedGdS2nXk"
      },
      "source": [
        "Seleccionamos todas las columnas. Asimismo, definimos los datos correspondientes a las etiquetas (variable de salida)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 903,
      "metadata": {
        "id": "t3injtSr2nXk"
      },
      "outputs": [],
      "source": [
        "X = dataset.data\n",
        "y = dataset.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3ZqY5zx2nXl"
      },
      "source": [
        "### Selección de la técnica (algoritmo)\n",
        "En esta subsección se van a crear un par de modelos a partir de los datos conocidos y estimar su precisión sobre datos nuevos. Para ello vamos a realizar los siguientes pasos:\n",
        "- Crear un dataset de validación con una parte de los datos disponibles.\n",
        "- Construir dos modelos diferentes para predecir, a partir de los datos de entrada recogidos en el dataset, si se trata de un cáncer de mama o no.\n",
        "- Aplicar los modelos para las predicciones y obtener las métricas\n",
        "- Seleccionar el mejor de los dos modelos.\n",
        "\n",
        "#### Creación del conjunto de datos de validación\n",
        "Sabemos que debemos entrenar las técnicas de modo que aprendan a clasificar si los datos de entrada corresponden a un cáncer de mama o no. Ello permitirá obtener los modelos respectivos. Allí surgirá una pregunta: ¿Cómo saber si nuestro modelo es bueno?. Para resolver esto vamos a usar las métricas vistas en una sesión anterior, relacionadas a la Matriz de Confusión.  Dichas métricas permiten evaluar la «calidad» de un modelo basado en Machine Learning.\n",
        "\n",
        "Con esa finalidad se separa la data en un conjunto de datos para el entrenamiento y en un segundo conjunto con datos para la validación, es decir, para probar los modelos; para ello, reservaremos un 20% de los datos del dataset original. Así, aplicándolo a este conjunto de validación, podremos comprobar cómo funciona el modelo, aquel que generamos entrenando el respectivo algoritmo con el 80% restante.\n",
        "\n",
        "Para tal efecto, se importan desde *sklearn* los módulos necesarios. Asimismo, se escalarán todos los datos de modo que no haya diferencia en el orden de magnitud en las atributos de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 974,
      "metadata": {
        "id": "adqaYeP82nXm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "#Se escalan todos los datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "escalar = StandardScaler()\n",
        "X_train = escalar.fit_transform(X_train)\n",
        "X_test = escalar.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJtQdCif2nXo"
      },
      "source": [
        "### Construcción de los modelos\n",
        "Como a priori no sabemos qué técnicas (algoritmos) pueden funcionar mejor para este problema, vamos a probar con 2 diferentes, ambos no lineales. Las gráficas iniciales ya indican que podemos ir por buen camino, porque se aprecia que algunas clase. Vamos a evaluar los siguientes algoritmos:\n",
        "\n",
        "*\tRegresión logística (LR)\n",
        "\n",
        "*\tk-Vecinos más cercanos (k-NN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eshJC_OR2nXq"
      },
      "source": [
        "### Regresión Logística\n",
        "Definimos la primera técnica a utilizar, en este caso la denominada Regresión Logística. Desde el *sklearn* importaremos los módulos que se requieren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr2zVH9-2nXr"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "algoritmo = LogisticRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QFjc5jN2nXr"
      },
      "source": [
        "#### Entrenamiento del modelo\n",
        "Una vez implementada la técnica en el entorno del *sklearn*, se entrena el modelo con el algoritmo respectivo usando la data de entrenamiento (X_train, y_train)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 976,
      "metadata": {
        "id": "cnvS3ELH2nXs",
        "outputId": "43f2b9df-da83-41cd-f6f0-a32b321b39be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-100 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-100 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-100 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-100 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-100 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-100 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-100 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-100 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-100 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-100 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-100 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-100 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-100 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-100 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-100 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-100 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-100 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-100 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-100 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-100\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" checked><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 976,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "algoritmo.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAv3gsG92nXt"
      },
      "source": [
        "#### Aplicación del modelo para hacer predicciones\n",
        "\n",
        "Ha llegado el momento de poner a prueba el modelo creado a partir de los datos de entrenamiento. Con esa finalidad, debemos aplicarlo a esa parte del dataset original que separamos al principio como dataset de validación. Como se dispone de los valores correctos de clasificación, y no se han usado en el entrenamiento del modelo (tampoco se usaron los datos sobre los atributos de entrada), si comparamos los valores reales con los predichos por el modelo sabremos si el modelo está funcionando correctamente o  no; incluso se podrá cuantificar en qué medida lo está haciendo.\n",
        "\n",
        "A continuación, se realiza la predicción y se verifica, usando la matriz de confusión, el comportamiento del modelo mediante las métricas *exactitud* y *precisión* ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1048,
      "metadata": {
        "id": "dWXVzJBb2nXu",
        "outputId": "91ebeca8-21b7-4a89-ed09-0004db1904c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz de Confusión:\n",
            "[[45  2]\n",
            " [ 2 65]]\n",
            "Precisión del modelo:\n",
            "0.9701492537313433\n",
            "Exactitud del modelo:\n",
            "0.9649122807017544\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
        "#Se escalan todos los datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "escalar = StandardScaler()\n",
        "X_train = escalar.fit_transform(X_train)\n",
        "X_test = escalar.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "algoritmo = LogisticRegression()\n",
        "\n",
        "algoritmo.fit(X_train, y_train)\n",
        "\n",
        "y_pred = algoritmo.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matriz = confusion_matrix(y_test, y_pred)\n",
        "print('Matriz de Confusión:')\n",
        "print(matriz)\n",
        "#Precisión del modelo\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precisión del modelo:')\n",
        "print(precision)\n",
        "#Exactitud del modelo\n",
        "from sklearn.metrics import accuracy_score\n",
        "exactitud = accuracy_score(y_test, y_pred)\n",
        "print('Exactitud del modelo:')\n",
        "print(exactitud)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04RZ-E_C2nXv"
      },
      "source": [
        "### k-NN\n",
        "Implementaremos mediante las funciones necesarias la técnica llama k-Vecinos Más Cercanos. Enseguida, análogamente a lo realizado para la Regresión Logística, se entrenará el modelo y se verificará usando otra vez la matriz de confusión y la métrica *precisión* el desempeño del modelo\n",
        "\n",
        "#### Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYLkHhBy2nXw",
        "outputId": "a742fe62-97a3-43b6-c112-18fada41dfdf"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "algoritmo = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "#Entreno el modelo\n",
        "algoritmo.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m2f94TX2nXw"
      },
      "source": [
        "#### Aplicación del modelo para hacer predicciones\n",
        "Ahora se realiza la predicción y la verificación del desempeño:\n",
        "Para aplicar el  modelo basado en el algoritmo k-NN, no tenemos más que ejecutar el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1306,
      "metadata": {
        "id": "eNCjdzqJ2nXx",
        "outputId": "b149e9ee-aad3-48aa-9eb8-8e69d745499f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz de Confusión:\n",
            "[[42  5]\n",
            " [ 0 67]]\n",
            "Precisión del modelo:\n",
            "0.9305555555555556\n",
            "Exactitud del modelo:\n",
            "0.956140350877193\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
        "#Se escalan todos los datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "escalar = StandardScaler()\n",
        "X_train = escalar.fit_transform(X_train)\n",
        "X_test = escalar.transform(X_test)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "algoritmo = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "#Entreno el modelo\n",
        "algoritmo.fit(X_train, y_train)\n",
        "\n",
        "y_pred = algoritmo.predict(X_test)\n",
        "#Verifico la matriz de Confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matriz = confusion_matrix(y_test, y_pred)\n",
        "print('Matriz de Confusión:')\n",
        "print(matriz)\n",
        "#Precisión del modelo\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precisión del modelo:')\n",
        "print(precision)\n",
        "#Exactitud del modelo\n",
        "from sklearn.metrics import accuracy_score\n",
        "exactitud = accuracy_score(y_test, y_pred)\n",
        "print('Exactitud del modelo:')\n",
        "print(exactitud)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzd1180k2nXx"
      },
      "source": [
        "### Elección del mejor modelo\n",
        "Al ejecutar la celda, se observan los estimadores para cada modelo. De esta forma, es posible compararlos y elegir el modelo que funciona mejor. A partir de  los resultados obtenidos, observamos que el modelo que da un mayor valor de exactitud es la Regresión Logística (94%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-n_MQMI2nXy"
      },
      "source": [
        "## Ejercicios\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ejercicio 1\n",
        "- En la aplicación de la técnica k-NN se ha usado la distancia Minkowski. Si se usa la distancia Euclidiana, mejoran los resultados?.\n",
        "- Comparativamente con los resultados obtenidos con la Regresión Logística, se mantiene que ésta consigue mejores resultados?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Según la documentación de sklearn, el valor de `p` puede ser 1 o 2:\n",
        "\n",
        "- `p = 1` → Distancia de Manhattan  \n",
        "- `p = 2` → Distancia Euclidiana\n",
        "\n",
        "En el modelo desarrollado se usa la Distancia Euclidiana (`p=2`), obteniendo una exactitud de **0.9737**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1296,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz de Confusión:\n",
            "[[44  3]\n",
            " [ 1 66]]\n",
            "Precisión del modelo:\n",
            "0.9565217391304348\n",
            "Exactitud del modelo:\n",
            "0.9649122807017544\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
        "#Se escalan todos los datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "escalar = StandardScaler()\n",
        "X_train = escalar.fit_transform(X_train)\n",
        "X_test = escalar.transform(X_test)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "algoritmo = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 1)\n",
        "#Entreno el modelo\n",
        "algoritmo.fit(X_train, y_train)\n",
        "y_pred = algoritmo.predict(X_test)\n",
        "#Verifico la matriz de Confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matriz = confusion_matrix(y_test, y_pred)\n",
        "print('Matriz de Confusión:')\n",
        "print(matriz)\n",
        "#Precisión del modelo\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precisión del modelo:')\n",
        "print(precision)\n",
        "#Exactitud del modelo\n",
        "from sklearn.metrics import accuracy_score\n",
        "exactitud = accuracy_score(y_test, y_pred)\n",
        "print('Exactitud del modelo:')\n",
        "print(exactitud)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ejercicio 2\n",
        "- Hemos basado el modelo en las técnicas llamadas Regresión Logística y k-NN, obteniéndose   buenos resultados tanto en exactitud como en precisión para la primera;  los valores de precisión para k-NN, según se pudo observar, también son buenos. Aplique ahora las  técnicas denominadas SVC, Árboles de Decisión y Bosques Aleatorios.\n",
        "- Compare los resultados que obtiene con los obtenidos con las dos primeras técnicas. Determine la mejor técnica (use Accuracy para determinarlo).\n",
        "**Nota**: puede usar diferentes medidas de evaluación.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Usando la técnica SVC:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz de Confusión:\n",
            "[[46  1]\n",
            " [ 1 66]]\n",
            "Precisión del modelo:\n",
            "0.9850746268656716\n",
            "Exactitud del modelo:\n",
            "0.9824561403508771\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
        "#Se escalan todos los datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "escalar = StandardScaler()\n",
        "X_train = escalar.fit_transform(X_train)\n",
        "X_test = escalar.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "algoritmo = SVC(kernel = 'linear')\n",
        "#Entreno el modelo\n",
        "algoritmo.fit(X_train, y_train)\n",
        "y_pred = algoritmo.predict(X_test)\n",
        "#Verifico la matriz de Confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matriz = confusion_matrix(y_test, y_pred)\n",
        "print('Matriz de Confusión:')\n",
        "print(matriz)\n",
        "#Precisión del modelo\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precisión del modelo:')\n",
        "print(precision)\n",
        "#Exactitud del modelo\n",
        "from sklearn.metrics import accuracy_score\n",
        "exactitud = accuracy_score(y_test, y_pred)\n",
        "print('Exactitud del modelo:')\n",
        "print(exactitud)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Usando la técnica Árbol de Decisión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1242,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz de Confusión:\n",
            "[[44  3]\n",
            " [ 5 62]]\n",
            "Precisión del modelo:\n",
            "0.9538461538461539\n",
            "Exactitud del modelo:\n",
            "0.9298245614035088\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
        "#Se escalan todos los datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "escalar = StandardScaler()\n",
        "X_train = escalar.fit_transform(X_train)\n",
        "X_test = escalar.transform(X_test)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "algoritmo = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "#Entreno el modelo\n",
        "algoritmo.fit(X_train, y_train)\n",
        "y_pred = algoritmo.predict(X_test)\n",
        "#Verifico la matriz de Confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matriz = confusion_matrix(y_test, y_pred)\n",
        "print('Matriz de Confusión:')\n",
        "print(matriz)\n",
        "#Precisión del modelo\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precisión del modelo:')\n",
        "print(precision)\n",
        "#Exactitud del modelo\n",
        "from sklearn.metrics import accuracy_score\n",
        "exactitud = accuracy_score(y_test, y_pred)\n",
        "print('Exactitud del modelo:')\n",
        "print(exactitud)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Usando la técnica Bosques Aleatorios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1256,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz de Confusión:\n",
            "[[45  2]\n",
            " [ 1 66]]\n",
            "Precisión del modelo:\n",
            "0.9705882352941176\n",
            "Exactitud del modelo:\n",
            "0.9736842105263158\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
        "#Se escalan todos los datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "escalar = StandardScaler()\n",
        "X_train = escalar.fit_transform(X_train)\n",
        "X_test = escalar.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "algoritmo = RandomForestClassifier(criterion = 'entropy', random_state = 0)\n",
        "#Entreno el modelo\n",
        "algoritmo.fit(X_train, y_train)\n",
        "y_pred = algoritmo.predict(X_test)\n",
        "#Verifico la matriz de Confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matriz = confusion_matrix(y_test, y_pred)\n",
        "print('Matriz de Confusión:')\n",
        "print(matriz)\n",
        "#Precisión del modelo\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precisión del modelo:')\n",
        "print(precision)\n",
        "#Exactitud del modelo\n",
        "from sklearn.metrics import accuracy_score\n",
        "exactitud = accuracy_score(y_test, y_pred)\n",
        "print('Exactitud del modelo:')\n",
        "print(exactitud)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ejercicio 3\n",
        "- Estudie si hay algún método que permita determinar el valor óptimo del parámetro `k`. Por ejemplo, si considera ahora tres conjuntos de datos para resolver el mismo problema con el algoritmo k-NN: conjunto de entrenamiento, conjunto de prueba falso y conjunto de prueba; y usa el  conjunto de prueba falso para optimizar el parámetro *k* del algoritmo k-NN, obtendrá un valor óptimo de `k`?.\n",
        "- Entrene y valide el modelo obtenido. Compare sus resultados con los obtenidos en el ejemplo presentado (este mismo documento)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con p=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1302,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best k from validation: 3\n",
            "Accuracy on test set: 0.956140350877193\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Paso 1: División del dataset\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
        "\n",
        "# Paso 2: Escalar los datos\n",
        "escalar = StandardScaler()\n",
        "X_train = escalar.fit_transform(X_train)\n",
        "X_val = escalar.transform(X_val)\n",
        "X_test = escalar.transform(X_test)\n",
        "\n",
        "# Paso 3: Búsqueda del mejor k\n",
        "accuracies = []\n",
        "k_values = range(1, 21)\n",
        "\n",
        "for k in k_values:\n",
        "    model = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=1)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    acc = accuracy_score(y_val, y_val_pred)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "best_k = k_values[np.argmax(accuracies)]\n",
        "print(f\"Best k from validation: {best_k}\")\n",
        "\n",
        "# Paso 4: Evaluación final\n",
        "final_model = KNeighborsClassifier(n_neighbors=best_k, metric='minkowski', p=1)\n",
        "final_model.fit(X_train, y_train)\n",
        "y_test_pred = final_model.predict(X_test)\n",
        "final_acc = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Accuracy on test set: {final_acc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con p=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1307,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best k from validation: 4\n",
            "Accuracy on test set: 0.9385964912280702\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Paso 1: División del dataset\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
        "\n",
        "# Paso 2: Escalar los datos\n",
        "escalar = StandardScaler()\n",
        "X_train = escalar.fit_transform(X_train)\n",
        "X_val = escalar.transform(X_val)\n",
        "X_test = escalar.transform(X_test)\n",
        "\n",
        "# Paso 3: Búsqueda del mejor k\n",
        "accuracies = []\n",
        "k_values = range(1, 21)\n",
        "\n",
        "for k in k_values:\n",
        "    model = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    acc = accuracy_score(y_val, y_val_pred)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "best_k = k_values[np.argmax(accuracies)]\n",
        "print(f\"Best k from validation: {best_k}\")\n",
        "\n",
        "# Paso 4: Evaluación final\n",
        "final_model = KNeighborsClassifier(n_neighbors=best_k, metric='minkowski', p=2)\n",
        "final_model.fit(X_train, y_train)\n",
        "y_test_pred = final_model.predict(X_test)\n",
        "final_acc = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Accuracy on test set: {final_acc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd-1v5_P2nXy"
      },
      "source": [
        "### Instrucciones para el envío de la solución\n",
        "\n",
        "La solución de la \"Práctica Guiada de Laboratorio 7 - IA 2025-1 G1 EPISW\" podrá enviarse al correo electrónico rmaguinap@unmsm.edu.pe, hasta las 23:59 h del Jueves 15 de Mayo del 2025, en un archivo con extensión .ipynb.\n",
        "\n",
        "El documento deberá tener las sgtes características:\n",
        "\n",
        "- Nombre del archivo: solPGL7_IA_2025-1_EPISW_G1_nombre-apellidos_...alumno1_nombre-apellidos_alumno3.ipynb.\n",
        "\n",
        "- Todas las preguntas de la Práctica deben responderse en un cuaderno computacional interactivo (**Sugerencia**: obtener una copia de este documento y desarrollar en éllas las respectivas soluciones); la solución a cada pregunta debe registrarse en una celda debajo del planteamiento de la misma, mencionando explícitamente como subtítulo: \"Solución del ejercicio n\", donde \"n\" corresponde al número del ejercicio."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
